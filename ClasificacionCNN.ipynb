{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ltabares/ClassificationCNNPneumonnia/blob/main/ClasificacionCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/ltabares/ClassificationCNNPneumonnia.git"
      ],
      "metadata": {
        "id": "8A5L4drIbN2A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa6a20ef-fea2-4cea-dcb8-57a6059d4f86"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ClassificationCNNPneumonnia' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nueva secci√≥n"
      ],
      "metadata": {
        "id": "-0CBhrHbbXWm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Referencies**\n",
        "\n",
        "\n",
        "1.   To build a CNN using upload images\n",
        "\n",
        "      https://www.tensorflow.org/tutorials/load_data/images\n",
        "\n",
        "2.   Equalization Histogram\n",
        "\n",
        "    https://towardsdatascience.com/image-augmentation-for-deep-learning-using-keras-and-histogram-equalization-9329f6ae5085\n",
        "    https://www.youtube.com/watch?v=mSbJ1Rqhze0\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aUD_ZVbUX37w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Functions\n",
        "#Contrast adjustment using ecualization histogram\n",
        "\n",
        "def contraste_img_eh(cat, path_data, type_image, size_image, path_data_he):\n",
        "  #Args:\n",
        "    #cat: category\n",
        "    #path_data: path where the original data are saved\n",
        "    #type_image: type of image (in this case jpeg)\n",
        "    #size_image:size of image\n",
        "    #path_data_he: path wherethe ecualizated image data are saved\n",
        "    os.chdir(path_data + cat + '/')\n",
        "    file_name_image = [file for file in glob.glob('*.' + type_image)]\n",
        "    image = [load_img(path_data + cat + '/'+ x, target_size = (size_image,size_image)) for x in file_name_image]\n",
        "    image_eh = list(map(ImageOps.equalize, image))\n",
        "    print(file_name_image)\n",
        "    for i in range(0, len(image_eh)):\n",
        "      image_eh[i].save(path_data_he + cat + \"/\" + file_name_image[i])\n"
      ],
      "metadata": {
        "id": "zRuGR87f6Q4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdZECf2r46Ra",
        "outputId": "67d86637-87bc-4ff4-b8af-6e5593982081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, glob\n",
        "\n",
        "import tensorflow as tf\n",
        "#from tensorflow.keras.preprocessing.image import load_img\n",
        "from keras_preprocessing.image import load_img\n",
        "\n",
        "from PIL import Image, ImageOps \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow # to show images in Google Colab\n",
        "# To mount Google Drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzJrCfH7ioJf"
      },
      "outputs": [],
      "source": [
        "#Configuration\n",
        "\n",
        "#Paths\n",
        "path_data_train = '/gdrive/MyDrive/Colab Notebooks/CNN Pneumonia/train/'\n",
        "path_data_train_he = '/gdrive/MyDrive/Colab Notebooks/CNN Pneumonia/train_he/'\n",
        "\n",
        "path_data_test = '/gdrive/MyDrive/Colab Notebooks/CNN Pneumonia/test/'\n",
        "path_data_test_he = '/gdrive/MyDrive/Colab Notebooks/CNN Pneumonia/test_he/'\n",
        "\n",
        "#Categories\n",
        "cat = ['NORMAL', 'PNEUMONIA']\n",
        "\n",
        "#Type of images\n",
        "type_image = 'jpeg'\n",
        "\n",
        "#If we want to apply ecualization hisogram over the original data and save them in a new folder \n",
        "#This is made in the fisrt running\n",
        "eh = False\n",
        "\n",
        "#Size of the images\n",
        "size_image = 224\n",
        "\n",
        "#Size of the batches\n",
        "batch_size = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHZfMkSfjsCs",
        "outputId": "3a3571f9-f2e5-45bd-8946-2670a4dd2ca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos NORMAL : 1341\n",
            "Datos PNEUMONIA : 3875\n"
          ]
        }
      ],
      "source": [
        "#Amount of origianl data\n",
        "for cat_ in cat:\n",
        "  print('Datos ' + cat_ + ' : ' + str(len(os.listdir(path_data_train + cat_))))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if eh:\n",
        "  contraste_img_eh('NORMAL', path_data_train, type_image, size_image, path_data_train_he)\n",
        "  contraste_img_eh('PNEUMONIA', path_data_train, type_image, size_image, path_data_train_he)\n",
        "  contraste_img_eh('NORMAL', path_data_test, type_image, size_image, path_data_test_he)\n",
        "  contraste_img_eh('PNEUMONIA', path_data_test, type_image, size_image, path_data_test_he)\n",
        "\n",
        "  #Amount of new ecualizated images. \n",
        "  #testing we haven't lost any image\n",
        "  for cat_ in cat:\n",
        "    print('Datos ' + cat_ + ' : ' + str(len(os.listdir(path_data_train_he + cat_))))"
      ],
      "metadata": {
        "id": "lQXj6-VI4Il-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-vMKBLZ_D0I",
        "outputId": "25232663-a25a-47f7-94a0-0743080ae37c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5216 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "#Get the data from the directory and creat a BatchDataset object for trainnig set\n",
        "train_data = tf.keras.utils.image_dataset_from_directory(\n",
        "  path_data_train_he,\n",
        "  labels = 'inferred',\n",
        "  class_names= ['NORMAL', 'PNEUMONIA'],\n",
        "  color_mode = 'grayscale',\n",
        "  shuffle= True, \n",
        "  seed= 123,\n",
        "  image_size= (size_image, size_image),\n",
        "  batch_size= batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqgVz9zyFw1v",
        "outputId": "23e22af0-de58-420c-92a8-8295d37355b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 624 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "#Get the data from the directory and creat a BatchDataset object for test set\n",
        "test_data = tf.keras.utils.image_dataset_from_directory(\n",
        "  path_data_test_he,\n",
        "  labels = 'inferred',\n",
        "  class_names= ['NORMAL', 'PNEUMONIA'],\n",
        "  color_mode = 'grayscale',\n",
        "  shuffle= True,\n",
        "  seed= 123,\n",
        "  image_size= (size_image, size_image),\n",
        "  batch_size= batch_size)\n",
        "\n",
        "\n",
        "y_test = np.concatenate([y for x, y in test_data], axis=0)\n",
        "x_test = np.concatenate([x for x, y in test_data], axis=0)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld-sSF0EGGcz",
        "outputId": "bd15577f-bb5b-4c1f-8e3e-cd4b086b5239"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15, 224, 224, 1)\n",
            "(15,)\n"
          ]
        }
      ],
      "source": [
        "for image_batch, labels_batch in train_data:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfAwhYBnIpzg",
        "outputId": "62a9b16d-4835-43f8-a2bd-efe9315a0ab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El valor m√°ximo de pixel es : 255.0\n"
          ]
        }
      ],
      "source": [
        "#Processing data\n",
        "#1)Rescaling the images--> values[0,1]\n",
        "#Get the max value of one image\n",
        "max_value = tf.reduce_max(np.array(load_img(path_data_train_he + 'NORMAL/'+ 'NORMAL2-IM-1423-0001.jpeg', target_size = (size_image,size_image)), dtype= 'float32'))\n",
        "print('El valor m√°ximo de pixel es :', max_value.numpy().max())\n",
        "\n",
        "resc = tf.keras.Sequential([tf.keras.layers.Rescaling(scale= 1./max_value.numpy().max(), offset= 0.0, name= 'rescaladoImagen')])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXXGP0i1qSfo"
      },
      "outputs": [],
      "source": [
        "#2)Zoom in \n",
        "zoom_in = tf.keras.Sequential([tf.keras.layers.RandomZoom(height_factor= [-0.1, -0.2], width_factor= [-0.1, -0.2], name= 'zoomInImagen')])\n",
        "\n",
        "\n",
        "#3)Rotation \n",
        "rotation = tf.keras.Sequential(tf.keras.layers.RandomRotation([-0.05, 0.05], fill_mode='nearest', name = 'rotationImage'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apzK8UcZ_EzW"
      },
      "outputs": [],
      "source": [
        "#CNN\n",
        "filter_conv1 = 16\n",
        "size_filter1 = (5,5)\n",
        "size_pool1= (2,2)\n",
        "\n",
        "filter_conv2 = 32\n",
        "size_filter2 = (5,5)\n",
        "size_pool2= (2,2)\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "#NN\n",
        "neuron_dense1 = 120\n",
        "drop_out = 0.5\n",
        "\n",
        "num_cat = len(cat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZa4dFO4xiJl"
      },
      "outputs": [],
      "source": [
        "modelo = tf.keras.Sequential([\n",
        "    resc, \n",
        "    zoom_in,\n",
        "    rotation,\n",
        "    tf.keras.layers.Conv2D(filter_conv1, size_filter1, padding = 'same', activation= 'relu', name = 'conv1'), \n",
        "    tf.keras.layers.MaxPooling2D(pool_size= size_pool1, name = 'pooling1'),\n",
        "    tf.keras.layers.Conv2D(filter_conv2, size_filter2, padding = 'same', activation= 'relu', name = 'conv2'), \n",
        "    tf.keras.layers.MaxPooling2D(pool_size= size_pool2, name = 'pooling2'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(neuron_dense1, activation = 'relu', name = 'FC1'),\n",
        "    tf.keras.layers.Dropout(drop_out), \n",
        "    tf.keras.layers.Dense(num_cat, activation='softmax', name = 'output')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTa3Z845b2qL"
      },
      "outputs": [],
      "source": [
        "modelo.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KruU10Iudp79",
        "outputId": "60d65e93-97d1-498c-e17c-7a54a48e1f51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "348/348 [==============================] - 539s 2s/step - loss: 0.3732 - accuracy: 0.8422 - val_loss: 0.4132 - val_accuracy: 0.8077\n",
            "Epoch 2/5\n",
            "348/348 [==============================] - 219s 629ms/step - loss: 0.2457 - accuracy: 0.8959 - val_loss: 0.6160 - val_accuracy: 0.7885\n",
            "Epoch 3/5\n",
            "348/348 [==============================] - 219s 629ms/step - loss: 0.2146 - accuracy: 0.9168 - val_loss: 0.4464 - val_accuracy: 0.7821\n",
            "Epoch 4/5\n",
            "348/348 [==============================] - 218s 627ms/step - loss: 0.1912 - accuracy: 0.9225 - val_loss: 0.4244 - val_accuracy: 0.7901\n",
            "Epoch 5/5\n",
            "348/348 [==============================] - 218s 626ms/step - loss: 0.1715 - accuracy: 0.9346 - val_loss: 0.4544 - val_accuracy: 0.8510\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f699645bcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "modelo.fit(\n",
        "  train_data,\n",
        "  validation_data = test_data,\n",
        "  epochs = epochs\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "mount_file_id": "1Yi9DviiniznCMYdiFkhXORR24P2F88sZ",
      "authorship_tag": "ABX9TyMx5j/JMs55Wa2HWHjkWqfl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}